# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2017, hyperledger
# This file is distributed under the same license as the hyperledger-fabricdocs package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
# 
# Translators:
# 王伟兵 <wbwang@inspur.com>, 2019
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: hyperledger-fabricdocs master\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-06-01 12:09+0800\n"
"PO-Revision-Date: 2019-04-22 20:01+0000\n"
"Last-Translator: 王伟兵 <wbwang@inspur.com>, 2019\n"
"Language-Team: Chinese (China) (https://www.transifex.com/hyperledger/teams/97220/zh_CN/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: zh_CN\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#: ../../source/orderer/ordering_service.md:1
msgid "The Ordering Service"
msgstr ""

#: ../../source/orderer/ordering_service.md:3
msgid "Audience: Architects, ordering service admins, channel creators"
msgstr "涉众:架构师、排序服务管理员、通道创建者"

#: ../../source/orderer/ordering_service.md:5
msgid ""
"This topic serves as a conceptual introduction to the concept of ordering, "
"how orderers interact with peers, the role they play in a transaction flow, "
"and an overview of the currently available implementations of the ordering "
"service, with a particular focus on the Raft ordering service "
"implementation."
msgstr ""
"这个话题是一个概念性的介绍顺序的概念,排序器与peer相互作用,如何在一个交易流程中所发挥的作用,和当前可用的排序服务的实现概述,尤其关注 Raft "
"排序服务实现。"

#: ../../source/orderer/ordering_service.md:10
msgid "What is ordering?"
msgstr ""

#: ../../source/orderer/ordering_service.md:12
msgid ""
"Many distributed blockchains, such as Ethereum and Bitcoin, are not "
"permissioned, which means that any node can participate in the consensus "
"process, wherein transactions are ordered and bundled into blocks. Because "
"of this fact, these systems rely on probabilistic consensus algorithms which"
" eventually guarantee ledger consistency to a high degree of probability, "
"but which are still vulnerable to divergent ledgers (also known as a ledger "
"\"fork\"), where different participants in the network have a different view"
" of the accepted order of transactions."
msgstr ""
"许多分布式区块链，如以太坊(Ethereum)和比特币(Bitcoin)，都不是许可链的，这意味着任何节点都可以参与共识过程，在共识过程中，交易被排序并捆绑成区块。因为这个事实,这些系统依靠概率共识算法最终保证账本一致性高的概率,但仍容易受到不同的账本(有时也称为一个账本“分叉”),在网络中不同的参与者对于交易顺序有不同的观点。"

#: ../../source/orderer/ordering_service.md:21
msgid ""
"Hyperledger Fabric works differently. It features a kind of a node called an"
" orderer (it's also known as an \"ordering node\") that does this "
"transaction ordering, which along with other nodes forms an ordering "
"service. Because Fabric's design relies on deterministic consensus "
"algorithms, any block a peer validates as generated by the ordering service "
"is guaranteed to be final and correct. Ledgers cannot fork the way they do "
"in many other distributed blockchains."
msgstr ""
"超级账本Fabric的工作方式不同。它具有一种称为排序器的节点(也称为“排序节点”)，它执行交易排序，并与其他节点一起形成一个排序服务。因为Fabric的设计依赖于确定性的共识算法，所以由排序服务生成的任何区块由peer验证都能保证是最终的和正确的。账本不能像在其他分布式区块链中那样分叉。"

#: ../../source/orderer/ordering_service.md:29
msgid ""
"In addition to promoting finality, separating the endorsement of chaincode "
"execution (which happens at the peers) from ordering gives Fabric advantages"
" in performance and scalability, eliminating bottlenecks which can occur "
"when execution and ordering are performed by the same nodes."
msgstr ""
"除了促进确定性之外，将链码执行的背书(发生在peer)与排序分离，还在性能和可伸缩性方面提供了Fabric的优势，消除了由相同节点执行和排序时可能出现的瓶颈。"

#: ../../source/orderer/ordering_service.md:34
msgid "Orderer nodes and channel configuration"
msgstr ""

#: ../../source/orderer/ordering_service.md:36
msgid ""
"In addition to their ordering role, orderers also maintain the list of "
"organizations that are allowed to create channels. This list of "
"organizations is known as the \"consortium\", and the list itself is kept in"
" the configuration of the \"orderer system channel\" (also known as the "
"\"ordering system channel\"). By default, this list, and the channel it "
"lives on, can only be edited by the orderer admin. Note that it is possible "
"for an ordering service to hold several of these lists, which makes the "
"consortium a vehicle for Fabric multi-tenancy."
msgstr ""
"除了排序角色之外，排序器还维护允许创建通道的组织列表。此组织列表称为“联盟”，列表本身保存在“排序器系统通道”(也称为“排序系统通道”)的配置中。默认情况下，此列表及其所在的通道只能由排序器管理员编辑。请注意，排序服务可以保存这些列表中的几个，这使得联盟成为Fabric多租户的载体。"

#: ../../source/orderer/ordering_service.md:44
msgid ""
"Orderers also enforce basic access control for channels, restricting who can"
" read and write data to them, and who can configure them. Remember that who "
"is authorized to modify a configuration element in a channel is subject to "
"the policies that the relevant administrators set when they created the "
"consortium or the channel. Configuration transactions are processed by the "
"orderer, as it needs to know the current set of policies to execute its "
"basic form of access control. In this case, the orderer processes the "
"configuration update to make sure that the requestor has the proper "
"administrative rights. If so, the orderer validates the update request "
"against the existing configuration, generates a new configuration "
"transaction, and packages it into a block that is relayed to all peers on "
"the channel. The peers then processs the configuration transactions in order"
" to verify that the modifications approved by the orderer do indeed satisfy "
"the policies defined in the channel."
msgstr ""
"排序器还对通道执行基本访问控制，限制谁可以读写数据，以及谁可以配置数据。请记住，谁有权修改通道中的配置元素取决于相关管理员在创建联盟或通道时设置的策略。配置交易由排序器处理，因为它需要知道当前策略集合来执行其基本形式的访问控制。在这种情况下，排序器处理配置更新，以确保请求者拥有正确的管理权限。如果是，排序器将根据现有配置验证更新请求，生成一个新的配置交易，并将其打包到一个区块中，该区块将转发给通道上的所有peer。然后peer处理配置交易，以验证排序器批准的修改确实满足通道中定义的策略。"

#: ../../source/orderer/ordering_service.md:59
msgid "Orderer nodes and Identity"
msgstr ""

#: ../../source/orderer/ordering_service.md:61
msgid ""
"Everything that interacts with a blockchain network, including peers, "
"applications, admins, and orderers, acquires their organizational identity "
"from their digital certificate and their Membership Service Provider (MSP) "
"definition."
msgstr "与区块链网络交互的所有东西，包括peer、应用程序、管理员和排序器，都从它们的数字证书和成员服务提供者(MSP)定义中获取它们的组织身份。"

#: ../../source/orderer/ordering_service.md:65
msgid ""
"For more information about identities and MSPs, check out our documentation "
"on Identity and Membership."
msgstr "有关身份和MSP的更多信息，请查看我们关于身份和成员的文档。"

#: ../../source/orderer/ordering_service.md:68
msgid ""
"Just like peers, ordering nodes belong to an organization. And similar to "
"peers, a separate Certificate Authority (CA) should be used for each "
"organization. Whether this CA will function as the root CA, or whether you "
"choose to deploy a root CA and then intermediate CAs associated with that "
"root CA, is up to you."
msgstr ""
"与peer一样，排序节点属于组织。与peer类似，应该为每个组织使用单独的证书颁发机构(CA)。这个CA是否将作为根CA发挥作用，或者您是否选择部署根CA，然后部署与该根CA关联的中间CA，这取决于您。"

#: ../../source/orderer/ordering_service.md:73
msgid "Orderers and the transaction flow"
msgstr ""

#: ../../source/orderer/ordering_service.md:75
msgid "Phase one: Proposal"
msgstr ""

#: ../../source/orderer/ordering_service.md:77
msgid ""
"We've seen from our topic on Peers that they form the basis for a blockchain"
" network, hosting ledgers, which can be queried and updated by applications "
"through smart contracts."
msgstr "从我们对peer节点的讨论中，我们已经看到它们构成了区块链网络的基础，托管账本，应用程序可以通过智能合约查询和更新这些账本。"

#: ../../source/orderer/ordering_service.md:81
msgid ""
"Specifically, applications that want to update the ledger are involved in a "
"process with three phases that ensures all of the peers in a blockchain "
"network keep their ledgers consistent with each other."
msgstr "具体地说，希望更新账本的应用程序涉及到一个分三个阶段的过程，该过程确保区块链网络中的所有peer保持它们的账本彼此一致。"

#: ../../source/orderer/ordering_service.md:85
msgid ""
"In the first phase, a client application sends a transaction proposal to a "
"subset of peers that will invoke a smart contract to produce a proposed "
"ledger update and then endorse the results. The endorsing peers do not apply"
" the proposed update to their copy of the ledger at this time. Instead, the "
"endorsing peers return a proposal response to the client application. The "
"endorsed transaction proposals will ultimately be ordered into blocks in "
"phase two, and then distributed to all peers for final validation and commit"
" in phase three."
msgstr ""
"在第一阶段，客户端应用程序将交易提案发送给一组peer，这些peer将调用一个智能合约来生成一个提议的账本更新，然后背书结果。背书peer此时不将提案的更新应用于其账本副本。相反，背书的peer将向客户机应用程序返回一个提案响应。已背书的交易提案最终将在第二阶段被排序为区块，然后在第三阶段分发给所有peer进行最终验证和提交。"

#: ../../source/orderer/ordering_service.md:94
msgid ""
"For an in-depth look at the first phase, refer back to the Peers topic."
msgstr "要深入了解第一个阶段，请参阅peer主题。"

#: ../../source/orderer/ordering_service.md:96
msgid "Phase two: Ordering and packaging transactions into blocks"
msgstr ""

#: ../../source/orderer/ordering_service.md:98
msgid ""
"After the completion of the first phase of a transaction, a client "
"application has received an endorsed transaction proposal response from a "
"set of peers. It's now time for the second phase of a transaction."
msgstr "在完成交易的第一阶段之后，客户端应用程序已经从一组peer接收到一个经过背书的交易提案响应。现在是交易的第二阶段。"

#: ../../source/orderer/ordering_service.md:102
msgid ""
"In this phase, application clients submit transactions containing endorsed "
"transaction proposal responses to an ordering service node. The ordering "
"service creates blocks of transactions which will ultimately be distributed "
"to all peers on the channel for final validation and commit in phase three."
msgstr ""
"在此阶段，应用程序客户端将包含已背书交易提案响应的交易提交到排序服务节点。排序服务创建交易区块，这些交易区块最终将分发给通道上的所有peer，以便在第三阶段进行最终验证和提交。"

#: ../../source/orderer/ordering_service.md:107
msgid ""
"Ordering service nodes receive transactions from many different application "
"clients concurrently. These ordering service nodes work together to "
"collectively form the ordering service. Its job is to arrange batches of "
"submitted transactions into a well-defined sequence and package them into "
"blocks. These blocks will become the blocks of the blockchain!"
msgstr ""
"排序服务节点同时接收来自许多不同应用程序客户端的交易。这些排序服务节点一起工作，共同组成排序服务。它的工作是将提交的交易按定义良好的顺序安排成批次，并将它们打包成区块。这些区块将成为区块链的区块!"

#: ../../source/orderer/ordering_service.md:113
msgid ""
"The number of transactions in a block depends on channel configuration "
"parameters related to the desired size and maximum elapsed duration for a "
"block (BatchSize and BatchTimeout parameters, to be exact). The blocks are "
"then saved to the orderer's ledger and distributed to all peers that have "
"joined the channel. If a peer happens to be down at this time, or joins the "
"channel later, it will receive the blocks after reconnecting to an ordering "
"service node, or by gossiping with another peer. We'll see how this block is"
" processed by peers in the third phase."
msgstr ""
"区块中的交易数量取决于区块的期望大小和最大运行时间相关的通道配置参数(确切地说，是BatchSize和BatchTimeout参数)。然后将这些区块保存到排序器的账本中，并分发给已经加入通道的所有peer。如果此时恰好有一个peer关闭，或者稍后加入通道，则在重新连接到排序服务节点或与另一个peer通信（闲聊）之后，通道将接收到这些区块。我们将在第三阶段看到peer如何处理这个区块。"

#: ../../source/orderer/ordering_service.md:124
msgid ""
"The first role of an ordering node is to package proposed ledger updates. In"
" this example, application A1 sends a transaction T1 endorsed by E1 and E2 "
"to the orderer O1. In parallel, Application A2 sends transaction T2 endorsed"
" by E1 to the orderer O1. O1 packages transaction T1 from application A1 and"
" transaction T2 from application A2 together with other transactions from "
"other applications in the network into block B2. We can see that in B2, the "
"transaction order is T1,T2,T3,T4,T6,T5 -- which may not be the order in "
"which these transactions arrived at the orderer! (This example shows a very "
"simplified ordering service configuration with only one ordering node.)"
msgstr ""
"排序节点的第一个角色是打包提案的账本更新。在本例中，应用程序A1向排序器O1发送由E1和E2背书的交易T1。同时，应用程序A2将E1背书的交易T2发送给排序器O1。O1将来自应用程序A1的交易T1和来自应用程序A2的交易T2以及来自网络中其他应用程序的交易打包到区块B2中。我们可以看到，在B2中，交易顺序是T1、T2、T3、T4、T6、T5——这可能不是这些交易到达排序器的顺序!(这个例子显示了一个非常简单的排序服务配置，只有一个排序节点。)"

#: ../../source/orderer/ordering_service.md:134
msgid ""
"It's worth noting that the sequencing of transactions in a block is not "
"necessarily the same as the order received by the ordering service, since "
"there can be multiple ordering service nodes that receive transactions at "
"approximately the same time.  What's important is that the ordering service "
"puts the transactions into a strict order, and peers will use this order "
"when validating and committing transactions."
msgstr ""
"值得注意的是，一个区块中交易的顺序不一定与排序服务接收的顺序相同，因为可能有多个排序服务节点几乎同时接收交易。重要的是，排序服务将交易放入严格的顺序中，并且peer在验证和提交交易时将使用这个顺序。"

#: ../../source/orderer/ordering_service.md:141
msgid ""
"This strict ordering of transactions within blocks makes Hyperledger Fabric "
"a little different from other blockchains where the same transaction can be "
"packaged into multiple different blocks that compete to form a chain. In "
"Hyperledger Fabric, the blocks generated by the ordering service are final. "
"Once a transaction has been written to a block, its position in the ledger "
"is immutably assured. As we said earlier, Hyperledger Fabric's finality "
"means that there are no ledger forks --- validated transactions will never "
"be reverted or dropped."
msgstr ""
"区块内交易的严格排序使得超级账本Fabric与其他区块链稍有不同，在其他区块链中，相同的交易可以被打包成多个不同的区块，从而形成一个链。在超级账本Fabric中，由排序服务生成的区块是最终的。一旦一笔交易被写进一个区块，它在账本中的地位就得到了不可动摇的保证。正如我们前面所说，超级账本Fabric的终结性意味着没有账本分支——经过验证的交易永远不会被还原或删除。"

#: ../../source/orderer/ordering_service.md:150
msgid ""
"We can also see that, whereas peers execute smart contracts and process "
"transactions, orderers most definitely do not. Every authorized transaction "
"that arrives at an orderer is mechanically packaged in a block --- the "
"orderer makes no judgement as to the content of a transaction (except for "
"channel configuration transactions, as mentioned earlier)."
msgstr ""
"我们还可以看到，虽然peer执行智能合约并处理交易，但是排序器绝对不会这样做。到达排序器的每个授权交易都被机械地打包在一个区块中——排序器不判断交易的内容(前面提到的通道配置交易除外)。"

#: ../../source/orderer/ordering_service.md:156
msgid ""
"At the end of phase two, we see that orderers have been responsible for the "
"simple but vital processes of collecting proposed transaction updates, "
"ordering them, and packaging them into blocks, ready for distribution."
msgstr "在第二阶段的末尾，我们看到排序器负责收集提议的交易更新、排序它们并将它们打包成区块，以便分发，这些简单但重要的过程。"

#: ../../source/orderer/ordering_service.md:160
msgid "Phase three: Validation and commit"
msgstr ""

#: ../../source/orderer/ordering_service.md:162
msgid ""
"The third phase of the transaction workflow involves the distribution and "
"subsequent validation of blocks from the orderer to the peers, where they "
"can be applied to the ledger."
msgstr "交易工作流的第三个阶段涉及到从排序器到peer的区块的分发和随后的验证，这些区块可以应用到账本中。"

#: ../../source/orderer/ordering_service.md:166
msgid ""
"Phase 3 begins with the orderer distributing blocks to all peers connected "
"to it. It's also worth noting that not every peer needs to be connected to "
"an orderer --- peers can cascade blocks to other peers using the gossip "
"protocol."
msgstr ""
"阶段3从排序器将区块分发给连接到它的所有peer开始。同样值得注意的是，并不是每个peer都需要连接到一个排序器——peer可以使用gossip协议将区块级联到其他peer。"

#: ../../source/orderer/ordering_service.md:171
msgid ""
"Each peer will validate distributed blocks independently, but in a "
"deterministic fashion, ensuring that ledgers remain consistent. "
"Specifically, each peer in the channel will validate each transaction in the"
" block to ensure it has been endorsed by the required organization's peers, "
"that its endorsements match, and that it hasn't become invalidated by other "
"recently committed transactions which may have been in-flight when the "
"transaction was originally endorsed. Invalidated transactions are still "
"retained in the immutable block created by the orderer, but they are marked "
"as invalid by the peer and do not update the ledger's state."
msgstr ""
"每个peer将独立地验证分布式区块，但以确定的方式验证，确保账本保持一致。具体来说,每个peer的通道将区块中的每个交易进行验证,以确保得到需要的组织peer的背书,其背书吻合,它还没有被其他最近已提交交易搞失效。无效的交易仍然保留在排序器创建的不可变区块中，但是peer将它们标记为无效，并且不更新账本的状态。"

#: ../../source/orderer/ordering_service.md:182
msgid ""
"The second role of an ordering node is to distribute blocks to peers. In "
"this example, orderer O1 distributes block B2 to peer P1 and peer P2. Peer "
"P1 processes block B2, resulting in a new block being added to ledger L1 on "
"P1. In parallel, peer P2 processes block B2, resulting in a new block being "
"added to ledger L1 on P2. Once this process is complete, the ledger L1 has "
"been consistently updated on peers P1 and P2, and each may inform connected "
"applications that the transaction has been processed."
msgstr ""
"排序节点的第二个角色是将区块分发给peer节点。在本例中，排序器O1将区块B2分配给peer P1和peer P2。peer "
"P1处理区块B2，导致在P1上的账本L1中添加一个新区块。同时，peer "
"P2处理区块B2，从而将一个新区块添加到P2上的账本L1中。一旦这个过程完成，peer "
"P1和P2上的账本L1就会一直更新，并且每个账本L1都可以通知连接的应用程序交易已经被处理。"

#: ../../source/orderer/ordering_service.md:190
msgid ""
"In summary, phase three sees the blocks generated by the ordering service "
"applied consistently to the ledger. The strict ordering of transactions into"
" blocks allows each peer to validate that transaction updates are "
"consistently applied across the blockchain network."
msgstr ""
"总之，第三阶段看到的是由排序服务生成的区块一致地应用于账本。将交易严格地按区块排序，允许每个peer验证交易更新是否在整个区块链网络上一致地应用。"

#: ../../source/orderer/ordering_service.md:195
msgid "For a deeper look at phase 3, refer back to the Peers topic."
msgstr "要更深入地了解阶段3，请参阅peer主题。"

#: ../../source/orderer/ordering_service.md:197
msgid "Ordering service implementations"
msgstr ""

#: ../../source/orderer/ordering_service.md:199
msgid ""
"While every ordering service currently available handles transactions and "
"configuration updates the same way, there are nevertheless several different"
" implementations for achieving consensus on the strict ordering of "
"transactions between ordering service nodes."
msgstr "虽然当前可用的每个排序服务都以相同的方式处理交易和配置更新，但是仍然有几种不同的实现可以在排序服务节点之间就严格的交易排序达成共识。"

#: ../../source/orderer/ordering_service.md:204
msgid ""
"For information about how to stand up an ordering node (regardless of the "
"implementation the node will be used in), check out our documentation on "
"standing up an ordering node."
msgstr "有关如何建立排序节点(无论该节点将在什么实现中使用)的信息，请参阅关于建立排序节点的文档。"

#: ../../source/orderer/ordering_service.md:207
#: ../../source/orderer/ordering_service.md:237
msgid "Solo"
msgstr ""

#: ../../source/orderer/ordering_service.md:209
msgid ""
"The Solo implementation of the ordering service is aptly named: it features "
"only a single ordering node. As a result, it is not, and never will be, "
"fault tolerant. For that reason, Solo implementations cannot be considered "
"for production, but they are a good choice for testing applications and "
"smart contracts, or for creating proofs of concept. However, if you ever "
"want to extend this PoC network into production, you might want to start "
"with a single node Raft cluster, as it may be reconfigured to add additional"
" nodes."
msgstr ""

#: ../../source/orderer/ordering_service.md:218
#: ../../source/orderer/ordering_service.md:251
msgid "Raft"
msgstr ""

#: ../../source/orderer/ordering_service.md:220
msgid ""
"New as of v1.4.1, Raft is a crash fault tolerant (CFT) ordering service "
"based on an implementation of Raft protocol in etcd. Raft follows a \"leader"
" and follower\" model, where a leader node is elected (per channel) and its "
"decisions are replicated by the followers. Raft ordering services should be "
"easier to set up and manage than Kafka-based ordering services, and their "
"design allows different organizations to contribute nodes to a distributed "
"ordering service."
msgstr ""

#: ../../source/orderer/ordering_service.md:229
#: ../../source/orderer/ordering_service.md:432
msgid "Kafka"
msgstr ""

#: ../../source/orderer/ordering_service.md:231
msgid ""
"Similar to Raft-based ordering, Apache Kafka is a CFT implementation that "
"uses a \"leader and follower\" node configuration. Kafka utilizes a "
"ZooKeeper ensemble for management purposes. The Kafka based ordering service"
" has been available since Fabric v1.0, but many users may find the "
"additional administrative overhead of managing a Kafka cluster intimidating "
"or undesirable."
msgstr ""

#: ../../source/orderer/ordering_service.md:239
msgid ""
"As stated above, a Solo ordering service is a good choice when developing "
"test, development, or proofs-of-concept networks. For that reason, it is the"
" default ordering service deployed in our Build your first network "
"tutorial), as, from the perspective of other network components, a Solo "
"ordering service processes transactions identically to the more elaborate "
"Kafka and Raft implementations while saving on the administrative overhead "
"of maintaining and upgrading multiple nodes and clusters. Because a Solo "
"ordering service is not crash-fault tolerant, it should never be considered "
"a viable alternative for a production blockchain network. For networks which"
" wish to start with only a single ordering node but might wish to grow in "
"the future, a single node Raft cluster is a better option."
msgstr ""
"如上所述，在开发测试、开发或概念验证网络时，单独排序服务是一个不错的选择。出于这个原因,它是默认的排序服务部署在我们构建第一个网络教程),从其他网络组件的角度来看,一个Solo排序服务处理交易相同于更复杂的Kafka和Raft实现，而节省维护和升级多个节点和集群的管理开销。由于Solo排序服务不能容错，因此它永远不应该被认为是生产区块链网络的可行替代方案。对于只希望从单个排序节点开始但将来可能希望增长的网络，单节点Raft集群是更好的选择。"

#: ../../source/orderer/ordering_service.md:253
msgid ""
"For information on how to configure a Raft ordering service, check out our "
"documentation on configuring a Raft ordering service."
msgstr "有关如何配置Raft排序服务的信息，请参阅有关配置Raft排序服务的文档。"

#: ../../source/orderer/ordering_service.md:256
msgid ""
"The go-to ordering service choice for production networks, the Fabric "
"implementation of the established Raft protocol uses a \"leader and "
"follower\" model, in which a leader is dynamically elected among the "
"ordering nodes in a channel (this collection of nodes is known as the "
"\"consenter set\"), and that leader replicates messages to the follower "
"nodes. Because the system can sustain the loss of nodes, including leader "
"nodes, as long as there is a majority of ordering nodes (what's known as a "
"\"quorum\") remaining, Raft is said to be \"crash fault tolerant\" (CFT). In"
" other words, if there are three nodes in a channel, it can withstand the "
"loss of one node (leaving two remaining). If you have five nodes in a "
"channel, you can lose two nodes (leaving three remaining nodes)."
msgstr ""
"生产网络的排序服务选择,建立Raft协议的Fabric实现使用一个“领导者和跟随者”模式,一个领导者的动态排序节点中选出一个通道(这个集合的节点称为“同意者”),和领导者将信息复制到跟随者节点。因为系统可以承受节点的损失，包括领导者节点，只要还有大量的有序节点(称为“quorum”)剩余，Raft被称为“崩溃容错”(crash"
" fault tolerant, "
"CFT)。换句话说，如果一个通道中有三个节点，它可以承受一个节点的丢失(剩下两个)。如果一个通道中有五个节点，则可能会丢失两个节点(留下三个剩余节点)。"

#: ../../source/orderer/ordering_service.md:268
msgid ""
"From the perspective of the service they provide to a network or a channel, "
"Raft and the existing Kafka-based ordering service (which we'll talk about "
"later) are similar. They're both CFT ordering services using the leader and "
"follower design. If you are an application developer, smart contract "
"developer, or peer administrator, you will not notice a functional "
"difference between an ordering service based on Raft versus Kafka. However, "
"there are a few major differences worth considering, especially if you "
"intend to manage an ordering service:"
msgstr ""
"从它们提供给网络或通道的服务的角度来看，Raft和现有的基于kafka的排序服务我们将在稍后讨论)是相似的。它们都是使用领导者和跟随者设计的CFT排序服务。如果您是应用程序开发人员、智能合约开发人员或peer管理员，您不会注意到基于Raft和Kafka的排序服务之间的功能差异。然而，有几个主要的差异值得考虑，特别是如果你打算管理一个排序服务:"

#: ../../source/orderer/ordering_service.md:276
msgid ""
"Raft is easier to set up. Although Kafka has scores of admirers, even those "
"admirers will (usually) admit that deploying a Kafka cluster and its "
"ZooKeeper ensemble can be tricky, requiring a high level of expertise in "
"Kafka infrastructure and settings. Additionally, there are many more "
"components to manage with Kafka than with Raft, which means that there are "
"more places where things can go wrong. And Kafka has its own versions, which"
" must be coordinated with your orderers. With Raft, everything is embedded "
"into your ordering node."
msgstr ""

#: ../../source/orderer/ordering_service.md:284
msgid ""
"Kafka and Zookeeper are not designed to be run across large networks. They "
"are designed to be CFT but should be run in a tight group of hosts. This "
"means that practically speaking you need to have one organization run the "
"Kafka cluster. Given that, having ordering nodes run by different "
"organizations when using Kafka (which Fabric supports) doesn't give you much"
" in terms of decentralization because the nodes will all go to the same "
"Kafka cluster which is under the control of a single organization. With "
"Raft, each organization can have its own ordering nodes, participating in "
"the ordering service, which leads to a more decentralized system."
msgstr ""

#: ../../source/orderer/ordering_service.md:294
msgid ""
"Raft is supported natively. While Kafka-based ordering services are "
"currently compatible with Fabric, users are required to get the requisite "
"images and learn how to use Kafka and ZooKeeper on their own. Likewise, "
"support for Kafka-related issues is handled through Apache, the open-source "
"developer of Kafka, not Hyperledger Fabric. The Fabric Raft implementation, "
"on the other hand, has been developed and will be supported within the "
"Fabric developer community and its support apparatus."
msgstr ""

#: ../../source/orderer/ordering_service.md:302
msgid ""
"Where Kafka uses a pool of servers (called \"Kafka brokers\") and the admin "
"of the orderer organization specifies how many nodes they want to use on a "
"particular channel, Raft allows the users to specify which ordering nodes "
"will be deployed to which channel. In this way, peer organizations can make "
"sure that, if they also own an orderer, this node will be made a part of a "
"ordering service of that channel, rather than trusting and depending on a "
"central admin to manage the Kafka nodes."
msgstr ""

#: ../../source/orderer/ordering_service.md:310
msgid ""
"Raft is the first step toward Fabric's development of a byzantine fault "
"tolerant (BFT) ordering service. As we'll see, some decisions in the "
"development of Raft were driven by this. If you are interested in BFT, "
"learning how to use Raft should ease the transition."
msgstr ""

#: ../../source/orderer/ordering_service.md:315
msgid ""
"Note: Similar to Solo and Kafka, a Raft ordering service can lose "
"transactions after acknowledgement of receipt has been sent to a client. For"
" example, if the leader crashes at approximately the same time as a follower"
" provides acknowledgement of receipt. Therefore, application clients should "
"listen on peers for transaction commit events regardless (to check for "
"transaction validity), but extra care should be taken to ensure that the "
"client also gracefully tolerates a timeout in which the transaction does not"
" get committed in a configured timeframe. Depending on the application, it "
"may be desirable to resubmit the transaction or collect a new set of "
"endorsements upon such a timeout."
msgstr ""
"注:与Solo和Kafka类似，Raft排序服务在向客户发送收据确认后可能会丢失交易。例如，如果领导者崩溃的时间与跟随者崩溃的时间大致相同时提供接收确认。因此，无论如何，应用程序客户端都应该侦听peer的交易提交事件(检查交易有效性)，但是应该格外小心，以确保客户端还能优雅地容忍一个超时，在这个超时中，交易没有在配置的时间范围内提交。根据应用程序的不同，可能需要在这样的超时之后重新提交交易或收集一组新的背书。"

#: ../../source/orderer/ordering_service.md:325
msgid "Raft concepts"
msgstr ""

#: ../../source/orderer/ordering_service.md:327
msgid ""
"While Raft offers many of the same features as Kafka --- albeit in a simpler"
" and easier-to-use package --- it functions substantially different under "
"the covers from Kafka and introduces a number of new concepts, or twists on "
"existing concepts, to Fabric."
msgstr ""
"尽管Raft提供了许多与Kafka相同的功能(尽管是在一个更简单、更容易使用的包中)，但它在幕后的功能与Kafka有本质上的不同，并向Fabric引入了许多新概念，或对现有概念进行了扭曲。"

#: ../../source/orderer/ordering_service.md:332
msgid ""
"Log entry. The primary unit of work in a Raft ordering service is a \"log "
"entry\", with the full sequence of such entries known as the \"log\". We "
"consider the log consistent if a majority (a quorum, in other words) of "
"members agree on the entries and their order, making the logs on the various"
" orderers replicated."
msgstr ""
"日志条目。Raft排序服务中的主要工作单元是一个“日志条目”，其中包含称为“日志”的完整序列。如果大多数成员(换句话说是一个法定人数)同意条目及其顺序，从而复制不同排序器上的日志，那么我们认为日志是一致的。"

#: ../../source/orderer/ordering_service.md:337
msgid ""
"Consenter set. The ordering nodes actively participating in the consensus "
"mechanism for a given channel and receiving replicated logs for the channel."
" This can be all of the nodes available (either in a single cluster or in "
"multiple clusters contributing to the system channel), or a subset of those "
"nodes."
msgstr ""
"批准者集合。排序节点积极参与给定通道的共识机制，并接收该通道的复制日志。这可以是所有可用的节点(在单个集群中或者在多个集群中)，也可以是这些节点的子集。"

#: ../../source/orderer/ordering_service.md:343
msgid ""
"Finite-State Machine (FSM). Every ordering node in Raft has an FSM and "
"collectively they're used to ensure that the sequence of logs in the various"
" ordering nodes is deterministic (written in the same sequence)."
msgstr "有限状态机(FSM)。Raft中的每个排序节点都有一个FSM，它们共同用于确保各个排序节点中的日志序列是确定的(以相同的顺序编写)。"

#: ../../source/orderer/ordering_service.md:347
msgid ""
"Quorum. Describes the minimum number of consenters that need to affirm a "
"proposal so that transactions can be ordered. For every consenter set, this "
"is a majority of nodes. In a cluster with five nodes, three must be "
"available for there to be a quorum. If a quorum of nodes is unavailable for "
"any reason, the ordering service cluster becomes unavailable for both read "
"and write operations on the channel, and no new logs can be committed."
msgstr ""
"法定人数。描述需要确认提案以便能够对交易排序的最小同意人数。对于每个批准者集合，这是大多数节点。在具有五个节点的集群中，必须有三个节点可用，才能有一个法定人数。如果节点的法定人数因任何原因不可用，则排序服务集群对于通道上的读和写操作都不可用，并且不能提交任何新日志。"

#: ../../source/orderer/ordering_service.md:354
msgid ""
"Leader. This is not a new concept --- Kafka also uses leaders, as we've said"
" --- but it's critical to understand that at any given time, a channel's "
"consenter set elects a single node to be the leader (we'll describe how this"
" happens in Raft later). The leader is responsible for ingesting new log "
"entries, replicating them to follower ordering nodes, and managing when an "
"entry is considered committed. This is not a special type of orderer. It is "
"only a role that an orderer may have at certain times, and then not others, "
"as circumstances determine."
msgstr ""
"领导者。这并不是一个新概念——正如我们所说，Kafka也使用了领导者——但是在任何给定的时间，通道的批准者集合都选择一个节点作为领导者，这一点非常重要(我们稍后将在Raft中描述这是如何发生的)。领导者负责接收新的日志条目，将它们复制到跟随者的排序节点，并在认为提交了某个条目时进行管理。这不是一种特殊类型的排序器。它只是排序器在某些时候可能扮演的角色，而不是由环境决定的其他角色。"

#: ../../source/orderer/ordering_service.md:363
msgid ""
"Follower. Again, not a new concept, but what's critical to understand about "
"followers is that the followers receive the logs from the leader and "
"replicate them deterministically, ensuring that logs remain consistent. As "
"we'll see in our section on leader election, the followers also receive "
"\"heartbeat\" messages from the leader. In the event that the leader stops "
"sending those message for a configurable amount of time, the followers will "
"initiate a leader election and one of them will be elected the new leader."
msgstr ""
"跟随者。再次强调，这不是一个新概念，但是理解跟随者的关键是跟随者从领导者那里接收日志并确定地复制它们，确保日志保持一致。我们将在关于领导者选举的部分中看到，跟随者也会收到来自领导者的“心跳”消息。如果领导者在一段可配置的时间内停止发送这些消息，跟随者将发起一次领导者选举，其中一人将当选为新的领导者。"

#: ../../source/orderer/ordering_service.md:371
msgid "Raft in a transaction flow"
msgstr ""

#: ../../source/orderer/ordering_service.md:373
msgid ""
"Every channel runs on a separate instance of the Raft protocol, which allows"
" each instance to elect a different leader. This configuration also allows "
"further decentralization of the service in use cases where clusters are made"
" up of ordering nodes controlled by different organizations. While all Raft "
"nodes must be part of the system channel, they do not necessarily have to be"
" part of all application channels. Channel creators (and channel admins) "
"have the ability to pick a subset of the available orderers and to add or "
"remove ordering nodes as needed (as long as only a single node is added or "
"removed at a time)."
msgstr ""
"每个通道都在Raft协议的单独实例上运行，该协议允许每个实例选择不同的领导者。这种配置还允许在集群由不同组织控制的有序节点组成的用例中进一步分散服务。虽然所有Raft节点都必须是系统通道的一部分，但它们不一定必须是所有应用程序通道的一部分。通道创建者(和通道管理员)能够选择可用排序器的子集，并根据需要添加或删除排序节点(只要一次只添加或删除一个节点)。"

#: ../../source/orderer/ordering_service.md:382
msgid ""
"While this configuration creates more overhead in the form of redundant "
"heartbeat messages and goroutines, it lays necessary groundwork for BFT."
msgstr "虽然这种配置以冗余心跳消息和线程的形式产生了更多的开销，但它为BFT奠定了必要的基础。"

#: ../../source/orderer/ordering_service.md:385
msgid ""
"In Raft, transactions (in the form of proposals or configuration updates) "
"are automatically routed by the ordering node that receives the transaction "
"to the current leader of that channel. This means that peers and "
"applications do not need to know who the leader node is at any particular "
"time. Only the ordering nodes need to know."
msgstr ""
"在Raft中，交易(以提案或配置更新的形式)由接收交易的排序节点自动路由到该通道的当前领导者。这意味着peer和应用程序在任何特定时间都不需要知道谁是领导者节点。只有排序节点需要知道。"

#: ../../source/orderer/ordering_service.md:391
msgid ""
"When the orderer validation checks have been completed, the transactions are"
" ordered, packaged into blocks, consented on, and distributed, as described "
"in phase two of our transaction flow."
msgstr "当排序器验证检查完成后，将按照我们交易流程的第二阶段的描述，对交易进行排序、打包成区块、协商并分发。"

#: ../../source/orderer/ordering_service.md:395
msgid "Architectural notes"
msgstr ""

#: ../../source/orderer/ordering_service.md:397
msgid "How leader election works in Raft"
msgstr ""

#: ../../source/orderer/ordering_service.md:399
msgid ""
"Although the process of electing a leader happens within the orderer's "
"internal processes, it's worth noting how the process works."
msgstr "尽管选举领导者的过程发生在排序器的内部过程中，但是值得注意的是这个过程是如何工作的。"

#: ../../source/orderer/ordering_service.md:402
msgid ""
"Raft nodes are always in one of three states: follower, candidate, or "
"leader. All nodes initially start out as a follower. In this state, they can"
" accept log entries from a leader (if one has been elected), or cast votes "
"for leader. If no log entries or heartbeats are received for a set amount of"
" time (for example, five seconds), nodes self-promote to the candidate "
"state. In the candidate state, nodes request votes from other nodes. If a "
"candidate receives a quorum of votes, then it is promoted to a leader. The "
"leader must accept new log entries and replicate them to the followers."
msgstr ""
"Raft节点总是处于以下三种状态之一:跟随者、候选人或领导者。所有节点最初都是作为跟随者开始的。在这种状态下，他们可以接受来自领导者的日志条目(如果其中一个已经当选)，或者为领导者投票。如果在一段时间内没有接收到日志条目或心跳(例如，5秒)，节点将自我提升到候选状态。在候选状态中，节点从其他节点请求选票。如果候选人获得法定人数的选票，那么他就被提升为领导者。领导者必须接受新的日志条目并将其复制到跟随者。"

#: ../../source/orderer/ordering_service.md:411
msgid ""
"For a visual representation of how the leader election process works, check "
"out The Secret Lives of Data."
msgstr "要了解领导者选举过程的可视化表示，请查看数据的秘密生活。"

#: ../../source/orderer/ordering_service.md:414
msgid "Snapshots"
msgstr ""

#: ../../source/orderer/ordering_service.md:416
msgid ""
"If an ordering node goes down, how does it get the logs it missed when it is"
" restarted?"
msgstr "如果一个排序节点宕机，它如何在重新启动时获得它丢失的日志?"

#: ../../source/orderer/ordering_service.md:419
msgid ""
"While it's possible to keep all logs indefinitely, in order to save disk "
"space, Raft uses a process called \"snapshotting\", in which users can "
"define how many bytes of data will be kept in the log. This amount of data "
"will conform to a certain number of blocks (which depends on the amount of "
"data in the blocks. Note that only full blocks are stored in a snapshot)."
msgstr ""
"虽然可以无限期地保留所有日志，但是为了节省磁盘空间，Raft使用了一个称为“快照”的过程，在这个过程中，用户可以定义日志中要保留多少字节的数据。这个数据量将符合一定数量的区块(这取决于区块中的数据量)。注意，快照中只存储完整的区块)。"

#: ../../source/orderer/ordering_service.md:425
msgid ""
"For example, let's say lagging replica R1 was just reconnected to the "
"network. Its latest block is 100. Leader L is at block 196, and is "
"configured to snapshot at amount of data that in this case represents 20 "
"blocks. R1 would therefore receive block 180 from L and then make a Deliver "
"request for blocks 101 to 180. Blocks 180 to 196 would then be replicated to"
" R1 through the normal Raft protocol."
msgstr ""
"例如，假设滞后副本R1刚刚重新连接到网络。它最新的区块是100。领导者L位于第196块，并被配置为在本例中快照20区块数据量。R1因此将从L接收区块180，然后为区块101到180发送请求。区块180到196然后将通过正常Raft协议复制到R1。"

#: ../../source/orderer/ordering_service.md:434
msgid ""
"The other crash fault tolerant ordering service supported by Fabric is an "
"adaptation of a Kafka distributed streaming platform for use as a cluster of"
" ordering nodes. You can read more about Kafka at the Apache Kafka Web site,"
" but at a high level, Kafka uses the same conceptual \"leader and follower\""
" configuration used by Raft, in which transactions (which Kafka calls "
"\"messages\") are replicated from the leader node to the follower nodes. In "
"the event the leader node goes down, one of the followers becomes the leader"
" and ordering can continue, ensuring fault tolerance, just as with Raft."
msgstr ""
"Fabric支持的另一个容错崩溃排序服务是对Kafka分布式流平台的改编，将其用作排序节点集群。您可以在Apache "
"Kafka网站上阅读更多关于Kafka的信息，但是在更高的层次上，Kafka使用与Raft相同的概念上的“领导者和跟随者”配置，其中交易(Kafka称之为“消息”)从领导者节点复制到跟随者节点。在领导者节点宕机的情况下，一个跟随者成为领导者,"
" 排序可以继续，确保容错，就像Raft一样。"

#: ../../source/orderer/ordering_service.md:443
msgid ""
"The management of the Kafka cluster, including the coordination of tasks, "
"cluster membership, access control, and controller election, among others, "
"is handled by a ZooKeeper ensemble and its related APIs."
msgstr "Kafka集群的管理，包括任务协调、集群成员、访问控制和控制器选择等，由ZooKeeper集合及其相关api来处理。"

#: ../../source/orderer/ordering_service.md:447
msgid ""
"Kafka clusters and ZooKeeper ensembles are notoriously tricky to set up, so "
"our documentation assumes a working knowledge of Kafka and ZooKeeper. If you"
" decide to use Kafka without having this expertise, you should complete, at "
"a minimum, the first six steps of the Kafka Quickstart guide before "
"experimenting with the Kafka-based ordering service. You can also consult "
"this sample configuration file for a brief explanation of the sensible "
"defaults for Kafka and ZooKeeper."
msgstr ""
"Kafka集群和ZooKeeper 集合的设置是出了名的棘手，所以我们的文档假设您对Kafka和ZooKeeper "
"有一定的了解。如果您决定在不具备此专业知识的情况下使用Kafka，那么在试验基于Kafka的排序服务之前，至少应该完成Kafka快速入门指南的前六个步骤。您还可以参考这个示例配置文件来简要解释Kafka和ZooKeeper的合理默认值。"

#: ../../source/orderer/ordering_service.md:455
msgid ""
"To learn how to bring up a a Kafka-based ordering service, check out our "
"documentation on Kafka."
msgstr "要了解如何启动基于Kafka的排序服务，请查看我们关于Kafka的文档。"
